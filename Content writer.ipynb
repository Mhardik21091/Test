{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPjGfWBo/neme7sisucAKrH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mhardik21091/Test/blob/main/Content%20writer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5MEawKiu3TfZ",
        "outputId": "0e80fb0e-184e-4784-d9fc-cd502d118138"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.37.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.9.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n"
          ]
        }
      ],
      "source": [
        "pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "\n",
        "text_generator = pipeline(\"text-generation\")\n",
        "\n",
        "prompt = input(\"Enter a prompt: \")\n",
        "generated_text = text_generator(prompt, max_length=500, num_return_sequences=1)\n",
        "print(\"\\nGenerated text:\")\n",
        "for sequnce in generated_text:\n",
        "    generated_paragraphs = sequnce['generated_text'].split(\"\\n\\n\")\n",
        "for paragraph in generated_paragraphs:\n",
        "    print(paragraph)\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a8AXo-213yJ1",
        "outputId": "20d28ae1-f2ec-4ecc-8224-5c68ee7b0157"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to gpt2 and revision 6c0e608 (https://huggingface.co/gpt2).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter a prompt: World where\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Generated text:\n",
            "World where the whole family was in danger\".\n",
            "In a blog post issued yesterday, the pair were told: \"You've no idea the level of fear is already there in America, how many more people are in those jobs with no jobs if the economy isn't improving. You just want to sit up and get a job, if something happens you're going to be looking and there's too many people out there to get in. So, yes I was so impressed about the level of desperation people were now experiencing. But we just don't know how to tackle it.\n",
            "\"And that is the lesson for young people now in their 40s and 50s. Don't be afraid to find a job even if you think it's a life hell's end.\n",
            "\"We need to make sure it doesn't happen to anyone because it's just not happening to those of us that are doing it\".\n",
            "In the past, the Clintons have often been found guilty of lying about their role in a scheme to steal tens of billions of dollars from their company for years.\n",
            "In the early days of Bill's administration, the Clintons, including Bill Clinton's first wife, gave $250 million to the American Red Cross, which she did a couple of years after the first Bill gave him.\n",
            "They also contributed millions more to the Clinton Foundation.\n",
            "But once the scandal hit, it immediately turned to political meddling - because the Clinton family's influence was so massive, money was quickly funneled to Hillary Clinton.\n",
            "This time around, the campaign was going on without a leader. Instead, Obama, Clinton and their families took over the White House.\n",
            "In fact, according to several people close to the Clintons and those involved, the Obama administration was responsible for helping the Clintons with that work.\n",
            "The only real chance they got was from Hillary Clinton's campaign chair, Hilary Clinton, who was trying to get the attention of the White House.\n",
            "And the press then began to write about the White House's role in the White House scandal in an attempt to downplay it.\n",
            "In an interview with USA Today, Eric Bardo, Clinton's campaign chairman, said: \"I think everyone knows that the White House is going to go and get everything that's going to help Hillary Rodham as much as it can get on the agenda, as well as try to get her to accept a fair system that's designed to make our\n"
          ]
        }
      ]
    }
  ]
}